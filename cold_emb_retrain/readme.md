## Introduction

LightGCN을 전체 유저의 성능이 최대가 될 때까지 학습시킨 결과, 학습 후반부로 갈수록 cold user의 성능이 급격하게 하락함을 확인할 수 있었습니다. 물론 성능 감소가 일어나기 전에 학습을 멈추고 추론을 진행해도 되겠지만, 이렇게 얻은 cold user의 임베딩 또한 최적이 아님을 주장합니다. Cold user의 임베딩 입장에서 다른 warm user와 item의 임베딩은 일종의 학습 환경입니다. 하지만 cold user의 성능이 최대가 될 때 다른 유저와 아이템들이 충분히 학습되지 않았기에 cold user가 좋은 학습을 할 수 없다는 것입니다.

따라서 이러한 현상을 개선하고자, 모델이 완전히 학습을 완료한 뒤에 cold user의 임베딩만을 정규분포 상에서 랜덤하게 초기화해서 재학습을 진행하는 방법을 제안합니다.

## Installation

파이썬 3.10 혹은 그 이상의 버전을 설치 후 아래 명령어를 실행하여 필요한 라이브러리를 설치합니다.

```bash
pip install -r requirements.txt
```

## Usage

해당 폴더 내로 이동하고 main.py를 실행하여 제안한 방법론의 유효성을 검증할 수 있습니다.

```bash
python main.py --dataset ml-20m --retrain
```

dataset 인자로 ml-1m 혹은 ml-20m를 입력하여 사용할 데이터셋을 선택할 수 있습니다.

retrain 인자의 유무에 따라 이전에 학습한 모델을 불러오고 cold user의 embedding을 초기화시켜 재학습할지,
아님 모델을 처음부터 학습할지 선택할 수 있습니다.

## Results (ML-20M)

|         | Original (Best across all epochs) | Original (Last) | Retrained (1 epoch) |
|---------|-----------------------------------|-----------------|---------------------|
| 1-shot  | 0.1579                            | 0.1017          | 0.1733              |
| 3-shot  | 0.1966                            | 0.1749          | 0.2152              |
| 5-shot  | 0.2174                            | 0.2026          | 0.2300              |
| all     | 0.2154                            | 0.2154          | 0.2220              |

눈여겨볼 점은 재학습을 진행했을 시 도달하는 성능이 이전 모든 epoch에서의 cold user 성능보다도 높았다는 것입니다. 이러한 관측은 다른 임베딩들이 최적일 때 cold user의 학습이 개선될 것이라는 가설을 뒷받침해줍니다.
