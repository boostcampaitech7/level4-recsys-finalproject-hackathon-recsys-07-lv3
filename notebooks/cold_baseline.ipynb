{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/ephemeral/home/data/cold/'\n",
    "save_dir = '../saved'\n",
    "model_path = save_dir + 'ncf.pth'\n",
    "mode = 5\n",
    "\n",
    "full_df = pd.read_csv(path + 'full.csv')\n",
    "train_df = pd.read_csv(path + f'{mode}shot/train_{mode}.csv')\n",
    "\n",
    "val_k = pd.read_csv(path + f'{mode}shot/val_{mode}_k.csv')\n",
    "test_k = pd.read_csv(path + f'{mode}shot/test_{mode}_k.csv')\n",
    "\n",
    "val_n = pd.read_csv(path + f'{mode}shot/val_{mode}_n.csv')\n",
    "test_n = pd.read_csv(path + f'{mode}shot/test_{mode}_n.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindex dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = full_df['user_id'].unique()\n",
    "items = full_df['item_id'].unique()\n",
    "\n",
    "user2idx = {user: i for i, user in enumerate(users)}\n",
    "item2idx = {item: i for i, item in enumerate(items)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리인덱싱 수행\n",
    "train_df['user_id'] = train_df['user_id'].map(user2idx)\n",
    "train_df['item_id'] = train_df['item_id'].map(item2idx)\n",
    "\n",
    "val_k['user_id'] = val_k['user_id'].map(user2idx)\n",
    "val_k['item_id'] = val_k['item_id'].map(item2idx)\n",
    "\n",
    "test_k['user_id'] = test_k['user_id'].map(user2idx)\n",
    "test_k['item_id'] = test_k['item_id'].map(item2idx)\n",
    "\n",
    "val_n['user_id'] = val_n['user_id'].map(user2idx)\n",
    "val_n['item_id'] = val_n['item_id'].map(item2idx)\n",
    "\n",
    "test_n['user_id'] = test_n['user_id'].map(user2idx)\n",
    "test_n['item_id'] = test_n['item_id'].map(item2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "\n",
    "del full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_users = val_k['user_id'].unique()\n",
    "test_users = test_k['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {user_id: [item_ids]} 딕셔너리 생성, train 에서는 neg_sampling에서 마스킹으로, Top K 추천에서는 scores에 대한 마스킹으로 사용 됌\n",
    "train_user_train_items = {k: list(v['item_id'].values) for k, v in train_df.groupby('user_id')}\n",
    "val_user_train_items = {k: list(v['item_id'].values) for k, v in val_k.groupby('user_id')}\n",
    "test_user_train_items = {k: list(v['item_id'].values) for k, v in test_k.groupby('user_id')}\n",
    "\n",
    "# val, test 유저들에 대한 정답 아이템 리스트 딕셔너리\n",
    "val_actual = {k: list(v['item_id'].values) for k, v in val_n.groupby('user_id')}\n",
    "test_actual = {k: list(v['item_id'].values) for k, v in test_n.groupby('user_id')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_k, test_k, val_n, test_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create COO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coo_matrix(df, n_users, n_items):\n",
    "    # torch 텐서로 변환\n",
    "    user_id_tensor = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
    "    item_id_tensor = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
    "    label_tensor = torch.ones(len(df), dtype=torch.float32)\n",
    "\n",
    "    # COO 희소 텐서 생성\n",
    "    indices = torch.stack([user_id_tensor, item_id_tensor])\n",
    "    values = label_tensor\n",
    "    size = (n_users, n_items)  # 전체 유저 x 전체 아이템 크기로 지정\n",
    "\n",
    "    return torch.sparse_coo_tensor(indices, values, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coo = create_coo_matrix(train_df, n_users, n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRDataset(Dataset):\n",
    "    '''\n",
    "    베이지안 개인화 순위(BPR)를 위한 PyTorch 데이터셋.\n",
    "\n",
    "    args:\n",
    "        coo (torch.sparse.coo_tensor): COO 형식의 사용자-아이템 상호작용 행렬.\n",
    "        user_train_items (dict): 각 사용자가 상호작용한 아이템 목록을 매핑하는 딕셔너리.\n",
    "        n_negs (int): 긍정 샘플당 생성할 부정 샘플의 수. 기본값은 1.\n",
    "    '''\n",
    "    def __init__(self, coo, user_train_items, n_negs=1):\n",
    "        self.users, self.pos_items = coo._indices()\n",
    "        self.user_train_items = user_train_items\n",
    "        self.n_negs = n_negs\n",
    "        self.n_items = coo.shape[1]\n",
    "        self.n_inter = coo._values().shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_inter\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        pos_item = self.pos_items[idx]\n",
    "        neg_item = self._get_neg_item(user.item())\n",
    "        return user, pos_item, neg_item\n",
    "    \n",
    "    # def _get_neg_items(self, user):\n",
    "    #     neg_items = set()\n",
    "    #     while len(neg_items) < self.n_negs:\n",
    "    #         neg_item = torch.randint(0, self.n_items, (1,)).item()\n",
    "    #         if neg_item not in self.user_pos_items[user]:\n",
    "    #             neg_items.add(neg_item)\n",
    "    #     return torch.LongTensor(list(neg_items))\n",
    "    \n",
    "    def _get_neg_item(self, user):\n",
    "        train_items = set(self.user_train_items[user])\n",
    "        neg_item = torch.randint(0, self.n_items, (1,)).item()\n",
    "        while neg_item in train_items:\n",
    "            neg_item = torch.randint(0, self.n_items, (1,)).item()\n",
    "        return neg_item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BPRDataset(train_coo, train_user_train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim=64, dropout=0.2):\n",
    "        super(NCF, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        self.mlp = nn.Sequential(  # [batch_size, emb_dim * 2]\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(emb_dim * 2, emb_dim),  # [batch_size, emb_dim]\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(emb_dim, emb_dim // 2),  # [batch_size, emb_dim // 2]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(emb_dim // 2, 1)  # [batch_size, 1]\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_normal_(self.user_emb.weight)\n",
    "        nn.init.xavier_normal_(self.item_emb.weight)\n",
    "        for layer in self.mlp:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_emb(user)\n",
    "        item_emb = self.item_emb(item)\n",
    "        concat = torch.cat([user_emb, item_emb], dim=-1)  # [batch_size, emb_dim * 2]\n",
    "        return self.mlp(concat).squeeze()  # [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPR 손실 함수\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pos_scores, neg_scores):\n",
    "        return -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(model, user_id, num_items, top_k=10, user_train_items=None):\n",
    "    \"\"\"\n",
    "    단일 유저에 대해 전체 아이템에 대한 스코어를 계산한 후,\n",
    "    이미 학습에 활용된 아이템(train_items)이 있을 경우 이를 마스킹(-무한대로 대체)하고,\n",
    "    bn.argpartition을 활용해 상위 top_k 아이템을 효율적으로 추출하는 함수.\n",
    "    \n",
    "    args:\n",
    "        model: user_id와 item_id의 텐서를 입력받아 스코어를 반환하는 추천 모델.\n",
    "        user_id (int): 추천을 위한 대상 유저 ID.\n",
    "        num_items (int): 전체 아이템의 개수.\n",
    "        top_k (int): 추천할 아이템 수.\n",
    "        train_items (list 또는 np.array, optional): 학습 시 활용된 해당 유저의 아이템 인덱스 리스트.\n",
    "    \n",
    "    return:\n",
    "        추천 아이템 인덱스 리스트 (정렬되어 있음)\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # user_id를 전체 아이템 개수만큼 반복하여 텐서 생성\n",
    "    user_ids = torch.full((num_items,), user_id, dtype=torch.long).to(device)\n",
    "    # 모든 아이템의 인덱스 생성\n",
    "    item_ids = torch.arange(num_items, dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = model(user_ids, item_ids)\n",
    "    \n",
    "    # train_items가 제공되면 해당 아이템의 스코어를 마스킹 처리 (-무한대값으로 대체)\n",
    "    if user_train_items is not None:\n",
    "        # torch indexing은 list나 array로도 발동됨\n",
    "        scores[user_train_items] = -float('inf')\n",
    "    \n",
    "    # GPU에 있을 경우 CPU로 옮긴 후 numpy 배열로 변환\n",
    "    scores_np = scores.cpu().numpy()\n",
    "    \n",
    "    # bottleneck의 argpartition을 사용하여 상위 top_k의 후보 인덱스를 추출\n",
    "    # 음수 부호를 취해 내림차순 정렬 효과를 냄.\n",
    "    candidate_indices = bn.argpartition(-scores_np, top_k-1)[:top_k]\n",
    "    \n",
    "    # argpartition은 정렬되어 있지 않으므로, 위 후보들에 대해 추가 정렬(내림차순) 수행\n",
    "    sorted_top_indices = candidate_indices[np.argsort(-scores_np[candidate_indices])]\n",
    "    \n",
    "    return sorted_top_indices.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = set(predicted[:k])\n",
    "    return len(actual_set & predicted_at_k) / k\n",
    "\n",
    "def precision_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = set(predicted[:k])\n",
    "    return len(actual_set & predicted_at_k) / len(predicted_at_k)\n",
    "\n",
    "def ndcg_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = predicted[:k]\n",
    "    dcg = sum([1 / np.log2(i + 2) for i, p in enumerate(predicted_at_k) if p in actual_set])\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(len(actual_set), k))])\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def map_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = predicted[:k]\n",
    "    score = 0.0\n",
    "    hit_count = 0.0\n",
    "    for i, item in enumerate(predicted_at_k):\n",
    "        if item in actual_set:\n",
    "            hit_count += 1.0\n",
    "            score += hit_count / (i + 1)\n",
    "    return score / len(actual_set) if actual else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, user_list, n_items, top_k, user_train_items, user_actual):\n",
    "    \"\"\"\n",
    "    모델의 평가를 위해 전체 아이템에 대한 추천 리스트를 생성하고\n",
    "    recall@k 등의 평가 지표를 계산하는 함수.\n",
    "    \n",
    "    args:\n",
    "      model (nn.Module): 추천 스코어를 계산하는 모델.\n",
    "      user_list (iterable): 평가할 유저 ID 리스트.\n",
    "      n_items (int): 전체 아이템의 개수.\n",
    "      top_k (int): 상위 추천 아이템 수 (예: 10).\n",
    "      user_train_items (dict): 각 유저마다 학습에 사용된 아이템 인덱스 리스트 – 평가 시 해당 아이템은 마스킹 처리함.\n",
    "      user_actual (dict): 각 유저의 실제 정답(ground truth) 아이템 리스트.\n",
    "    \n",
    "    return:\n",
    "      전체 유저에 대한 평균 recall@k 값.\n",
    "    \"\"\"\n",
    "    model.eval()  # 평가 모드로 전환 (dropout, batchnorm 등 고정)\n",
    "    recalls, precisions, ndcgs, maps = [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user in tqdm(user_list, desc=\"Evaluating\", leave=False):\n",
    "            # 기존에 작성한 recommend_items 함수 사용 (학습에 사용한 아이템은 마스킹)\n",
    "            recommendations = recommend_items(model, user, n_items, top_k, user_train_items[user])\n",
    "            # 추천 결과와 실제 정답(dict나 list)에 따라 메트릭 계산\n",
    "            recalls.append(recall_at_k(user_actual[user], recommendations, top_k))\n",
    "            precisions.append(precision_at_k(user_actual[user], recommendations, top_k))\n",
    "            ndcgs.append(ndcg_at_k(user_actual[user], recommendations, top_k))\n",
    "            maps.append(map_at_k(user_actual[user], recommendations, top_k))\n",
    "\n",
    "    model.train()  # 평가 후 다시 학습 모드로 전환\n",
    "\n",
    "    metrics = {\n",
    "        'recall': np.mean(recalls),\n",
    "        'precision': np.mean(precisions),\n",
    "        'ndcg': np.mean(ndcgs),\n",
    "        'map': np.mean(maps),\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "emb_dim = 64\n",
    "dropout = 0.2\n",
    "model = NCF(n_users, n_items, emb_dim, dropout)\n",
    "model = model.to(device)\n",
    "criterion = BPRLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 104047/104047 [10:16<00:00, 168.87it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0875 | Recall@10: 0.0551, Precision@10: 0.0551, NDCG@10: 0.0992, MAP@10: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 104047/104047 [10:28<00:00, 165.57it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0800 | Recall@10: 0.0765, Precision@10: 0.0765, NDCG@10: 0.1173, MAP@10: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 104047/104047 [10:25<00:00, 166.29it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0768 | Recall@10: 0.0884, Precision@10: 0.0884, NDCG@10: 0.1292, MAP@10: 0.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 104047/104047 [10:14<00:00, 169.35it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0738 | Recall@10: 0.0637, Precision@10: 0.0637, NDCG@10: 0.1083, MAP@10: 0.0570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 104047/104047 [10:16<00:00, 168.76it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0706 | Recall@10: 0.0623, Precision@10: 0.0623, NDCG@10: 0.1017, MAP@10: 0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 104047/104047 [10:17<00:00, 168.61it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0683 | Recall@10: 0.0864, Precision@10: 0.0864, NDCG@10: 0.1390, MAP@10: 0.0711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 104047/104047 [10:17<00:00, 168.42it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0672 | Recall@10: 0.0795, Precision@10: 0.0795, NDCG@10: 0.1277, MAP@10: 0.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 104047/104047 [10:26<00:00, 165.96it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0663 | Recall@10: 0.0901, Precision@10: 0.0901, NDCG@10: 0.1456, MAP@10: 0.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 104047/104047 [10:23<00:00, 166.95it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0656 | Recall@10: 0.0718, Precision@10: 0.0718, NDCG@10: 0.1187, MAP@10: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 104047/104047 [10:31<00:00, 164.79it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0652 | Recall@10: 0.0734, Precision@10: 0.0734, NDCG@10: 0.1242, MAP@10: 0.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Metrics - Recall@10: 0.0901, Precision@10: 0.0901, NDCG@10: 0.1456, MAP@10: 0.0745\n",
      "Test Metrics - Recall@10: 0.0741, Precision@10: 0.0741, NDCG@10: 0.1267, MAP@10: 0.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "valid_interval = 1\n",
    "best_val_ndcg = -1\n",
    "best_val_metrics = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for user, pos_item, neg_item in tqdm(train_loader, desc=f'Training Epoch {epoch+1}'):\n",
    "        user = user.to(device)\n",
    "        pos_item = pos_item.to(device)\n",
    "        neg_item = neg_item.to(device)\n",
    "\n",
    "        pos_scores = model(user, pos_item)\n",
    "        neg_scores = model(user, neg_item)\n",
    "\n",
    "        loss = criterion(pos_scores, neg_scores)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    " # 평가: val_users, n_items, top_k, 그리고 유저별 학습/정답 아이템 정보 사용\n",
    "    if (epoch + 1) % valid_interval == 0:\n",
    "        # Evaluate on validation users\n",
    "        val_metrics = evaluate(model, val_users, n_items, 10, val_user_train_items, val_actual)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_train_loss:.4f} | '\n",
    "              f'Recall@10: {val_metrics['recall']:.4f}, Precision@10: {val_metrics['precision']:.4f}, '\n",
    "              f'NDCG@10: {val_metrics['ndcg']:.4f}, MAP@10: {val_metrics['map']:.4f}')\n",
    "\n",
    "        # Check if this is the best validation NDCG\n",
    "        if val_metrics['ndcg'] > best_val_ndcg:\n",
    "            best_val_ndcg = val_metrics['ndcg']\n",
    "            best_val_metrics = val_metrics\n",
    "            best_epoch = epoch+1\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f'Model saved to {model_path}')\n",
    "    else:\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_train_loss:.4f}')\n",
    "    \n",
    "# Evaluate on test users\n",
    "model.load_state_dict(torch.load('../saved/ncf.pth', weights_only=True))\n",
    "test_metrics = evaluate(model, test_users, n_items, 10, test_user_train_items, test_actual)\n",
    "\n",
    "# Print best validation metrics\n",
    "if best_val_metrics:\n",
    "    print(f'Best Epoch:{best_epoch}, Val Metrics - Recall@10: {best_val_metrics['recall']:.4f}, '\n",
    "          f'Precision@10: {best_val_metrics['precision']:.4f}, '\n",
    "          f'NDCG@10: {best_val_metrics['ndcg']:.4f}, MAP@10: {best_val_metrics['map']:.4f}')\n",
    "# Print test metrics\n",
    "print(f'Test Metrics - Recall@10: {test_metrics['recall']:.4f}, '\n",
    "      f'Precision@10: {test_metrics['precision']:.4f}, '\n",
    "      f'NDCG@10: {test_metrics['ndcg']:.4f}, MAP@10: {test_metrics['map']:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 안할 시 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../saved/ncf.pth', weights_only=True))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 유저에게 추천 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13754/13754 [00:15<00:00, 885.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# 빈 리스트를 생성하여 추천 결과를 저장\n",
    "recommendations = []\n",
    "\n",
    "# 각 사용자에 대해 추천 아이템을 생성하고 리스트에 추가\n",
    "for user_id in tqdm(test_users):\n",
    "    recommended_items = recommend_items(model, user_id, n_items, 10, test_user_train_items[user_id])\n",
    "    for item_id in recommended_items:\n",
    "        recommendations.append({'user_id': user_id, 'item_id': item_id})\n",
    "\n",
    "# 리스트를 데이터프레임으로 변환\n",
    "result = pd.DataFrame(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2user = {v: k for k, v in user2idx.items()}\n",
    "idx2item = {v: k for k, v in item2idx.items()}\n",
    "\n",
    "result['user_id'] = result['user_id'].map(idx2user)\n",
    "result['item_id'] = result['item_id'].map(idx2item)\n",
    "\n",
    "result.to_csv('../saved/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딕셔너리로 추천 결과 생성하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13754/13754 [00:15<00:00, 894.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# test_recommendations = {user_id: recommend_items(model, user_id, n_items, 10, test_user_train_items[user_id]) for user_id in tqdm(test_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.DataFrame([\n",
    "#     {'user_id': user, 'item_id': item}\n",
    "#     for user, items in test_recommendations.items()\n",
    "#     for item in items\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
