{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/ephemeral/home/data/cold/'\n",
    "mode = 5\n",
    "\n",
    "full_df = pd.read_csv(path + 'full.csv')\n",
    "train_df = pd.read_csv(path + f'{mode}shot/train_{mode}.csv')\n",
    "\n",
    "val_k = pd.read_csv(path + f'{mode}shot/val_{mode}_k.csv')\n",
    "test_k = pd.read_csv(path + f'{mode}shot/test_{mode}_k.csv')\n",
    "\n",
    "val_n = pd.read_csv(path + f'{mode}shot/val_{mode}_n.csv')\n",
    "test_n = pd.read_csv(path + f'{mode}shot/test_{mode}_n.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindex dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = full_df['user_id'].unique()\n",
    "items = full_df['item_id'].unique()\n",
    "\n",
    "user2idx = {user: i for i, user in enumerate(users)}\n",
    "item2idx = {item: i for i, item in enumerate(items)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리인덱싱 수행\n",
    "train_df['user_id'] = train_df['user_id'].map(user2idx)\n",
    "train_df['item_id'] = train_df['item_id'].map(item2idx)\n",
    "\n",
    "val_k['user_id'] = val_k['user_id'].map(user2idx)\n",
    "val_k['item_id'] = val_k['item_id'].map(item2idx)\n",
    "\n",
    "test_k['user_id'] = test_k['user_id'].map(user2idx)\n",
    "test_k['item_id'] = test_k['item_id'].map(item2idx)\n",
    "\n",
    "val_n['user_id'] = val_n['user_id'].map(user2idx)\n",
    "val_n['item_id'] = val_n['item_id'].map(item2idx)\n",
    "\n",
    "test_n['user_id'] = test_n['user_id'].map(user2idx)\n",
    "test_n['item_id'] = test_n['item_id'].map(item2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "\n",
    "del full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_users = val_k['user_id'].unique()\n",
    "test_users = test_k['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_pos_items = {k: list(v['item_id'].values) for k, v in train_df.groupby('user_id')}\n",
    "val_user_pos_items = {k: list(v['item_id'].values) for k, v in val_k.groupby('user_id')}\n",
    "test_user_pos_items = {k: list(v['item_id'].values) for k, v in test_k.groupby('user_id')}\n",
    "\n",
    "val_actual = {k: list(v['item_id'].values) for k, v in val_n.groupby('user_id')}\n",
    "test_actual = {k: list(v['item_id'].values) for k, v in test_n.groupby('user_id')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_k, test_k, val_n, test_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create COO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coo_matrix(df, n_users, n_items):\n",
    "    # torch 텐서로 변환\n",
    "    user_id_tensor = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
    "    item_id_tensor = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
    "    label_tensor = torch.ones(len(df), dtype=torch.float32)\n",
    "\n",
    "    # COO 희소 텐서 생성\n",
    "    indices = torch.stack([user_id_tensor, item_id_tensor])\n",
    "    values = label_tensor\n",
    "    size = (n_users, n_items)  # 전체 유저 x 전체 아이템 크기로 지정\n",
    "\n",
    "    return torch.sparse_coo_tensor(indices, values, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coo = create_coo_matrix(train_df, n_users, n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRDataset(Dataset):\n",
    "    '''\n",
    "    args:\n",
    "        coo: torch.sparse.coo_tensor, user-item interaction matrix\n",
    "        train: bool, train or test\n",
    "        n_negs: int, number of negative samples\n",
    "    '''\n",
    "    def __init__(self, coo, user_pos_items, n_negs=1):\n",
    "        self.users, self.pos_items = coo._indices()\n",
    "        self.user_pos_items = user_pos_items\n",
    "        self.n_negs = n_negs\n",
    "        self.n_items = coo.shape[1]\n",
    "        self.n_inter = coo._values().shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_inter\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        pos_item = self.pos_items[idx]\n",
    "        neg_item = self._get_neg_item(user)\n",
    "        return user, pos_item, neg_item\n",
    "    \n",
    "    # def _get_neg_items(self, user):\n",
    "    #     neg_items = set()\n",
    "    #     while len(neg_items) < self.n_negs:\n",
    "    #         neg_item = torch.randint(0, self.n_items, (1,)).item()\n",
    "    #         if neg_item not in self.user_pos_items[user]:\n",
    "    #             neg_items.add(neg_item)\n",
    "    #     return torch.LongTensor(list(neg_items))\n",
    "    \n",
    "    def _get_neg_item(self, user):\n",
    "        user_pos_items = set(self.user_pos_items[user])\n",
    "        neg_item = torch.randint(0, self.n_items)\n",
    "        while neg_item in user_pos_items:\n",
    "            neg_item = torch.randint(0, self.n_items)\n",
    "        return neg_item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BPRDataset(train_coo, train_user_pos_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user, pos_item, neg_items in train_loader:\n",
    "#     print(user.shape)\n",
    "#     print(pos_item.shape)\n",
    "#     print(neg_items.shape)\n",
    "#     print(neg_items[:, 0].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim=64, dropout=0.2):\n",
    "        super(NCF, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        self.mlp = nn.Sequential(  # [batch_size, emb_dim * 2]\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(emb_dim * 2, emb_dim),  # [batch_size, emb_dim]\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(emb_dim, emb_dim // 2),  # [batch_size, emb_dim // 2]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(emb_dim // 2, 1)  # [batch_size, 1]\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_normal_(self.user_emb.weight)\n",
    "        nn.init.xavier_normal_(self.item_emb.weight)\n",
    "        for layer in self.mlp:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "                nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_emb(user)\n",
    "        item_emb = self.item_emb(item)\n",
    "        concat = torch.cat([user_emb, item_emb], dim=-1)  # [batch_size, emb_dim * 2]\n",
    "        return self.mlp(concat).squeeze()  # [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPR 손실 함수\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pos_scores, neg_scores):\n",
    "        return -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "emb_dim = 64\n",
    "dropout = 0.2\n",
    "model = NCF(n_users, n_items, emb_dim, dropout)\n",
    "model.to(device)\n",
    "criterion = BPRLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1224\n",
      "Epoch 2, Loss: 0.1054\n",
      "Epoch 3, Loss: 0.0966\n",
      "Epoch 4, Loss: 0.0932\n",
      "Epoch 5, Loss: 0.0904\n",
      "Epoch 6, Loss: 0.0873\n",
      "Epoch 7, Loss: 0.0848\n",
      "Epoch 8, Loss: 0.0830\n",
      "Epoch 9, Loss: 0.0817\n",
      "Epoch 10, Loss: 0.0810\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for user, pos_item, neg_item in tqdm(train_loader):\n",
    "        user = user.to(device)\n",
    "        pos_item = pos_item.to(device)\n",
    "        neg_item = neg_item.to(device)\n",
    "\n",
    "        pos_scores = model(user, pos_item)\n",
    "        neg_scores = model(user, neg_item)\n",
    "\n",
    "        loss = criterion(pos_scores, neg_scores)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'saved/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model_path = save_dir + 'ncf.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCF(\n",
       "  (user_emb): Embedding(137534, 64)\n",
       "  (item_emb): Embedding(24799, 64)\n",
       "  (mlp): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../saved/ncf.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def recommend_items(model, user_id, num_items, top_k=10, train_items=None):\n",
    "    \"\"\"\n",
    "    단일 유저에 대해 전체 아이템에 대한 스코어를 계산한 후,\n",
    "    이미 학습에 활용된 아이템(train_items)이 있을 경우 이를 마스킹(-무한대로 대체)하고,\n",
    "    bn.argpartition을 활용해 상위 top_k 아이템을 효율적으로 추출하는 함수.\n",
    "    \n",
    "    인자:\n",
    "        model: user_id와 item_id의 텐서를 입력받아 스코어를 반환하는 추천 모델.\n",
    "        user_id (int): 추천을 위한 대상 유저 ID.\n",
    "        num_items (int): 전체 아이템의 개수.\n",
    "        top_k (int): 추천할 아이템 수.\n",
    "        train_items (list 또는 np.array, optional): 학습 시 활용된 해당 유저의 아이템 인덱스 리스트.\n",
    "    \n",
    "    반환:\n",
    "        추천 아이템 인덱스 리스트 (정렬되어 있음)\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # user_id를 전체 아이템 개수만큼 반복하여 텐서 생성\n",
    "    user_ids = torch.full((num_items,), user_id, dtype=torch.long).to(device)\n",
    "    # 모든 아이템의 인덱스 생성\n",
    "    item_ids = torch.arange(num_items, dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = model(user_ids, item_ids)\n",
    "    \n",
    "    # train_items가 제공되면 해당 아이템의 스코어를 마스킹 처리 (-무한대값으로 대체)\n",
    "    if train_items is not None:\n",
    "        # torch indexing은 list나 array로도 발동됨\n",
    "        scores[train_items] = -float('inf')\n",
    "    \n",
    "    # GPU에 있을 경우 CPU로 옮긴 후 numpy 배열로 변환\n",
    "    scores_np = scores.cpu().numpy()\n",
    "    \n",
    "    # bottleneck의 argpartition을 사용하여 상위 top_k의 후보 인덱스를 추출\n",
    "    # 음수 부호를 취해 내림차순 정렬 효과를 냄.\n",
    "    candidate_indices = bn.argpartition(-scores_np, top_k-1)[:top_k]\n",
    "    \n",
    "    # argpartition은 정렬되어 있지 않으므로, 위 후보들에 대해 추가 정렬(내림차순) 수행\n",
    "    sorted_top_indices = candidate_indices[np.argsort(-scores_np[candidate_indices])]\n",
    "    \n",
    "    return sorted_top_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13753/13753 [00:22<00:00, 624.03it/s]\n"
     ]
    }
   ],
   "source": [
    "val_recommendations = {user_id: recommend_items(model, user_id, n_items, 10, val_user_pos_items[user_id]) for user_id in tqdm(val_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AutoRec(nn.Module):\n",
    "#     def __init__(self, num_users, num_items, hidden_units=256):\n",
    "#         super(AutoRec, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(num_users, hidden_units)\n",
    "#         self.item_embedding = nn.Embedding(num_items, hidden_units)\n",
    "#         self.fc1 = nn.Linear(hidden_units, hidden_units)\n",
    "#         self.fc2 = nn.Linear(hidden_units, 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, user_ids, item_ids):\n",
    "#         user_embeds = self.user_embedding(user_ids)\n",
    "#         item_embeds = self.item_embedding(item_ids)\n",
    "#         x = user_embeds * item_embeds\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         return self.fc2(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = set(predicted[:k])\n",
    "    return len(actual_set & predicted_at_k) / k\n",
    "\n",
    "def precision_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = set(predicted[:k])\n",
    "    return len(actual_set & predicted_at_k) / k\n",
    "\n",
    "def ndcg_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = predicted[:k]\n",
    "    dcg = sum([1 / np.log2(i + 2) for i, p in enumerate(predicted_at_k) if p in actual_set])\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(len(actual_set), k))])\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def mean_average_precision_at_k(actual, predicted, k):\n",
    "    actual_set = set(actual)\n",
    "    predicted_at_k = predicted[:k]\n",
    "    ap_sum = sum([(i + 1) / (idx + 1) for idx, i in enumerate(predicted_at_k) if i in actual_set])\n",
    "    return ap_sum / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07550352650331352"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list()\n",
    "for user in val_users:\n",
    "    results.append(recall_at_k(val_actual[user], val_recommendations[user], 10))\n",
    "sum(results) / len(val_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1277575648681164"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list()\n",
    "for user in val_users:\n",
    "    results.append(ndcg_at_k(val_actual[user], val_recommendations[user], 10))\n",
    "sum(results) / len(val_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.534017804484793"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list()\n",
    "for user in val_users:\n",
    "    results.append(mean_average_precision_at_k(val_actual[user], val_recommendations[user], 10))\n",
    "sum(results) / len(val_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = {}\n",
    "# for user in val_users:\n",
    "#     metrics['Recall@10'].append(recall_at_k(val_actual[user], val_recommendations[user], 10))\n",
    "# #     metrics['Precision@10'] = precision_at_k(val_actual[user], val_recommendations[user], 10)\n",
    "# #     metrics['NDCG@10'] = ndcg_at_k(val_actual[user], val_recommendations[user], 10)\n",
    "# #     metrics['MAP@10'] = mean_average_precision_at_k(val_actual[user], val_recommendations[user], 10)\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, test_loader, k_values):\n",
    "    model.eval()\n",
    "    results = {k: {\"recall\": [], \"precision\": [], \"ndcg\": [], \"map\": []} for k in k_values}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, ratings in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            user_ids, item_ids, ratings = user_ids.to(device), item_ids.to(device), ratings.to(device)\n",
    "            predictions = model(user_ids, item_ids)\n",
    "            \n",
    "            # 각 사용자에 대해 평가\n",
    "            for user, items, preds in zip(user_ids, item_ids, predictions):\n",
    "                actual = items[ratings == 1].tolist()\n",
    "                predicted = items[torch.argsort(preds, descending=True)].tolist()\n",
    "                \n",
    "                for k in k_values:\n",
    "                    results[k][\"recall\"].append(normalized_recall_at_k(actual, predicted, k))\n",
    "                    results[k][\"precision\"].append(normalized_precision_at_k(actual, predicted, k))\n",
    "                    results[k][\"ndcg\"].append(ndcg_at_k(actual, predicted, k))\n",
    "                    results[k][\"map\"].append(mean_average_precision_at_k(actual, predicted, k))\n",
    "\n",
    "    \n",
    "    # 결과 집계\n",
    "    aggregated_results = {\n",
    "        k: {metric: np.mean(values) for metric, values in results[k].items()}\n",
    "        for k in k_values\n",
    "    }\n",
    "    \n",
    "    return aggregated_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
